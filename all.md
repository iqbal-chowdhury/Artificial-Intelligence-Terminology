# Letter A
[*Return*](https://github.com/SyncedAI00/Artificial-Intelligence-Terminology/blob/master/README.md)

英文/缩写|汉语|来源&扩展
---|---|---
Absolute value rectiﬁcation|绝对值整流|[1]
Activation Function|激活函数|[[1]](https://www.jiqizhixin.com/articles/75832471-bf67-4450-9173-ada016694ee8) / [[2]](https://www.jiqizhixin.com/articles/343a4328-2915-4b20-a770-9e8bc74dfc1a)
Accumulated error backpropagation|累积误差逆传播|[1]
Adaptive Resonance Theory/ART|自适应谐振理论|[1]
Addictive model|加性模型|[1]
Adversarial example|对抗样本|[1]
Adversarial Networks|对抗网络|[1]
Affine Layer|仿射层|[1]
Affinity matrix|亲和矩阵|[1]
Agent|智能体|[[1]](https://www.jiqizhixin.com/articles/83490ca4-3bb9-40fa-9306-366902430ade) / [[2]](https://www.jiqizhixin.com/articles/c3cfa8fe-3f1e-49bc-ae5e-0ea0720c0dd3) / [[3]](https://www.jiqizhixin.com/articles/3b85b031-aabe-4814-9da2-708da822c15e) / [[4]](https://www.jiqizhixin.com/articles/e8ebba0d-0c7e-4a95-9428-b17513e950ef)
Algorithm|算法|[[1]](https://www.jiqizhixin.com/articles/99633338-62ff-460e-b313-0ab7a38d6592) / [[2]](https://www.jiqizhixin.com/articles/90a896ca-c170-4cb9-b388-e27972d9888e) / [[3]](https://www.jiqizhixin.com/articles/66d2b476-1f96-452a-8bfc-1fbc2104e935)
Alpha-beta pruning|α-β剪枝|[1]
Alternative splicing dataset|选择性剪接数据集|[1]
Ancestral Sampling|原始采样|[1]
Annealed importance sampling|退火重要采样|[1]
Anomaly detection|异常检测|[1]
Application-speciﬁc integrated circuit|专用集成电路|[1]
Approximate Bayesian computation|近似贝叶斯计算|[1]
Approximate inference|近似推断|[1]
Approximation|近似|[1]
Architecture|架构|[1]
Area Under ROC Curve/AUC|Roc 曲线下面积|[1]
Artificial General Intelligence/AGI|通用人工智能|[1]
Artificial Intelligence/AI|人工智能|[[1]](https://www.jiqizhixin.com/articles/6c4d3c08-7da7-4eb3-94e4-39a1c62f8f14) / [[2]](https://www.jiqizhixin.com/articles/becd2fae-251d-4a7b-9138-0c23abc37bec) / [[3]](https://www.jiqizhixin.com/articles/384306f4-c2c3-4e31-b35f-42b33b605d53)
Association analysis|关联分析|[1]
Asymptotically unbiased|渐近无偏|[1]
Asynchoronous Stochastic Gradient Descent|异步随机梯度下降|[1]
Attention mechanism|注意力机制|[[1]](https://www.jiqizhixin.com/articles/826db510-639e-4e3d-9c1e-65e2a5297ab2) / [[2]](https://www.jiqizhixin.com/articles/dc109d2e-b297-4017-807d-705900e4923e) / [[3]](https://www.jiqizhixin.com/articles/5be2c12a-0e58-45fe-8478-26528b14cced)
Attribute conditional independence assumption |属性条件独立性假设|[1]
Attribute space|属性空间|[1]
Attribute value|属性值|[1]
Augmented Lagrangian|增广拉格朗日法|[1]
Autoencoder|自编码器|[[1]](https://www.jiqizhixin.com/articles/fa8b9e4a-6c75-403c-880c-9e695d0280c8)
Automatic diﬀerentiation|自动微分|[1]
Automatic speech recognition/ASR|自动语音识别|[1]
Automatic summarization|自动摘要|[1]
Auto-regressive network|自回归网络|[1]
Average gradient|平均梯度|[1]
Average-Pooling|平均池化|[1]
# Letter B
[*Return*](https://github.com/SyncedAI00/Artificial-Intelligence-Terminology/blob/master/README.md)

英文/缩写|汉语|来源&扩展
---|---|---
Backpropagation/BP|反向传播|[[1]](https://www.jiqizhixin.com/articles/2533c5a5-af09-41c0-830a-7e075ad8ccd7)
Backpropagation Through Time|通过时间的反向传播|[1]
Bag of words/BoW|词袋|[1]
Base learner|基学习器|[1]
Base learning algorithm|基学习算法|[1]
Batch|批量|[1]
Batch Normalization/BN|批量归一化|[1]
Bayes decision rule |贝叶斯判定准则|[1]
Bayes error|贝叶斯误差|[1]
Bayes Model Averaging/BMA|贝叶斯模型平均|[1]
Bayes optimal classifier|贝叶斯最优分类器|[1]
Bayesian decision theory|贝叶斯决策论|[1]
Bayesian network|贝叶斯网络|[1]
Beam search|束搜索|[1]
Bechmark|基准|[1]
Belief network|信念网络|[1]
Between-class scatter matrix|类间散度矩阵|[1]
Bias|偏置 / 偏差|[1]
Biased|有偏|[1]
Biased importance sampling|有偏重要采样|[1]
Bias-variance decomposition|偏差-方差分解|[1]
Bias-Variance Dilemma|偏差 - 方差困境|[1]
Bi-directional Long-Short Term Memory/Bi-LSTM|双向长短期记忆|[1]
Binary classification|二分类|[1]
Binary relation|二元关系|[1]
Binary sparse coding|二值稀疏编码|[1]
Binomial distribution|二项分布|[1]
Binomial test|二项检验|[1]
Bi-partition|二分法|[1]
Block coordinate descent|块坐标下降|[1]
Block Gibbs Sampling|块吉布斯采样|[1]
Boltzmann distribution|玻尔兹曼分布|[1]
Boltzmann machine|玻尔兹曼机|[1]
Bootstrap sampling|自助采样法／可重复采样／有放回采样|[1]
Bootstrapping|自助法|[1]
Break-Event Point/BEP|平衡点|[1]
Bridge sampling|桥式采样|[1]
Broadcasting|广播|[1]
Burning-in|磨合|[1]
# Letter C
[*Return*](https://github.com/SyncedAI00/Artificial-Intelligence-Terminology/blob/master/README.md)

英文/缩写|汉语|来源&扩展
---|---|---
Calculus of variations|变分法|[1]
Calibration|校准|[1]
Cascade/Coalesced|级联|[1]
Cascade-Correlation|级联相关|[1]
Categorical attribute|离散属性|[1]
Categorical distribution|范畴分布|[1]
Causal factor|因果因子|[1]
Causal modeling|因果模型|[1]
Centered difference|中心差分|[1]
Central limit theorem|中心极限定理|[1]
Chain rule|链式法则|[1]
Chordal graph|弦图|[1]
Class-conditional probability|类条件概率|[1]
Classification and regression tree/CART|分类与回归树|[1]
Classifier|分类器|[1]
Class-imbalance|类别不平衡|[1]
Clip gradient|梯度截断|[1]
Clique potential|团势能|[1]
Closed-form|闭式|[1]
Cluster|簇/类/集群|[1]
Cluster analysis|聚类分析|[1]
Clustering|聚类|[1]
Clustering ensemble|聚类集成|[1]
Co-adapting|共适应|[1]
Coding matrix|编码矩阵|[1]
Collaborative filtering|协同过滤|[1]
COLT|国际学习理论会议|[1]
Committee-based learning	|基于委员会的学习|[1]
Competitive learning	|竞争型学习|[1]
Complete graph|完全图|[1]
Component learner	|组件学习器|[1]
Comprehensibility	|可解释性|[1]
Computation Cost|	计算成本|[1]
Computational Linguistics|	计算语言学|[1]
Computer vision|	计算机视觉|[1]
Concept drift|	概念漂移|[1]
Concept Learning System/CLS|	概念学习系统|[1]
Conditional entropy|条件熵|[1]
Conditional mutual information|	条件互信息|[1]
Conditional Probability Table/CPT|	条件概率表|[1]
Conditional random field/CRF|	条件随机场|[1]
Conditional risk |	条件风险|[1]
Confidence|	置信度|[1]
Confusion matrix	|混淆矩阵|[1]
Conjugate directions|共轭方向|[1]
Conjugate distribution|共轭分布|[1]
Conjugate gradient|共轭梯度|[1]
Connection weight	|连接权|[1]
Connectionism	|连结主义|[1]
Consistency	|一致性／相合性|[1]
Consistency convergence|一致性收敛|[1]
Contingency table	|列联表|[1]
Continuation method|延拓法|[1]
Continuous attribute	|连续属性|[1]
Contractive autoencoder|收缩自编码器|[1]
Convex optimization|凸优化|[1]
Convergence|	收敛|[1]
Conversational agent	|会话智能体|[1]
Convex optimization|凸优化|[1]
Convex quadratic programming 	|凸二次规划|[1]
Convexity|	凸性|[1]
Convolutional Boltzmann Machine|卷积玻尔兹曼机|[1]
Convolutional neural network/CNN|	卷积神经网络|[1]
Co-occurrence	|同现|[1]
Coordinate descent|坐标下降|[1]
Correlation coefficient	|相关系数|[1]
Cosine similarity|余弦相似度|[1]
Cost curve	|成本曲线|[1]
Cost Function	|成本函数|[1]
Cost matrix	|成本矩阵|[1]
Cost-sensitive	|成本敏感|[1]
Covariance|协方差|[1]
Covariance matrix|协方差矩阵|[1]
Cross entropy|	交叉熵|[1]
Cross validation	|交叉验证|[1]
Cross-correlation|互相关函数|[1]
Crowdsourcing	|众包|[1]
Cumulative function|累积函数|[1]
Curse of dimensionality|维度灾难|[1]
Cut point	|截断点|[1]
Cutting plane algorithm |	割平面法|[1]
# Letter D
[*Return*](https://github.com/SyncedAI00/Artificial-Intelligence-Terminology/blob/master/README.md)

英文/缩写|汉语|来源&扩展
---|---|---
Data generating distribution|数据生成分布|[1]
Data mining	|数据挖掘|[1]
Data parallelism|数据并行|[1]
Data set	|数据集|[1]
Dataset augmentation|数据集增强|[1]
Decision Boundary	|决策边界|[1]
Decision stump|	决策树桩|[1]
Decision tree	|决策树／判定树|[1]
Deduction	|演绎|[1]
Deep Belief Network	|深度信念网络|[1]
Deep Boltzmann Machine|深度玻尔兹曼机|[1]
Deep circuit|深度回路|[1]
Deep Convolutional Generative Adversarial Network/DCGAN|	深度卷积生成对抗网络|[1]
Deep generative model|深度生成模型|[1]
Deep learning|	深度学习|[1]
Deep neural network/DNN|	深度神经网络|[1]
Deep Q-Learning	|深度 Q 学习|[1]
Deep Q-Network	|深度 Q 网络|[1]
Denoising autoencoder|去噪自编码器|[1]
Denoising score matching|去噪得分匹配|[1]
Density estimation 	|密度估计|[1]
Density-based clustering|密度聚类|[1]
Detailed balance|细致平衡|[1]
Determinant|行列式|[1]
Diagonal matrix|对角矩阵|[1]
Differentiable neural computer|	可微分神经计算机|[1]
Diﬀerential entropy|微分熵|[1]
Diﬀerential equation|微分方程|[1]
Dimensionality reduction algorithm|	降维算法|[1]
Directed edge|有向边|[1]
Directed graphical model|有向图模型|[1]
Directional derivative|方向导数|[1]
Dirichlet distribution|狄利克雷分布|[1]
Disagreement measure	|不合度量|[1]
Discriminative model	|判别模型|[1]
Discriminator|	判别器|[1]
Discriminator network|判别器网络|[1]
Distance measure	|距离度量|[1]
Distance metric learning|距离度量学习|[1]
Distribution|	分布|[1]
Divergence|	散度|[1]
Diversity measure	|多样性度量／差异性度量|[1]
Domain adaption	|领域自适应|[1]
Double backprop|双反向传播|[1]
Doubly block circulant matrix|双重分块循环矩阵|[1]
Downsampling	|下采样|[1]
D-separation/Directed separation|有向分离|[1]
Dual problem |	对偶问题|[1]
Dummy node	|哑结点|[1]
Dynamic Fusion	|动态融合|[1]
Dynamic programming|动态规划|[1]
# Letter E
[*Return*](https://github.com/SyncedAI00/Artificial-Intelligence-Terminology/blob/master/README.md)

英文/缩写|汉语|来源&扩展
---|---|---
Echo state network|回声状态网络|[1]
Edge device|边缘设备|[1]
Eigendecomposition|特征分解|[1]
Eigenvalue|特征值|[1]
Eigenvalue decomposition|特征值分解|[1]
Eigenvector|特征向量|[1]
Element-wise product|元素对应乘积|[1]
Ellipsoid method|椭球法|[1]
Embedding	|嵌入|[1]
Emotional analysis	|情绪分析|[1]
Empirical conditional entropy|经验条件熵|[1]
Empirical entropy|经验熵|[1]
Empirical error|	经验误差|[1]
Empirical risk	|经验风险|[1]
End-to-End	|端到端|[1]
Energy-based model	|基于能量的模型|[1]
Ensemble learning|	集成学习|[1]
Ensemble pruning	|集成修剪|[1]
Epochs|轮数|[1]
Error Correcting Output Codes/ECOC	|纠错输出码|[1]
Error rate|错误率|[1]
Error-ambiguity decomposition|	误差-分歧分解|[1]
Euclidean distance|	欧氏距离|[1]
Euclidean norm|欧几里得范数|[1]
Evolutionary computation |演化计算|[1]
Expectation-Maximization/EM|	期望最大化|[1]
Expected loss |期望损失|[1]
Expert network|专家网络|[1]
Explaining away eﬀect|相消解释作用|[1]
Exploding Gradient Problem|	梯度爆炸问题|[1]
Exponential loss function |	指数损失函数|[1]
Extreme Learning Machine/ELM|超限学习机|[1]
# Letter F
[*Return*](https://github.com/SyncedAI00/Artificial-Intelligence-Terminology/blob/master/README.md)

英文/缩写|汉语|来源&扩展
---|---|---
Factor analysis|因子分析|[1]
Factorization|因子分解|[1]
Factors of variation|变差因素|[1]
False negative	|假负类|[1]
False positive|	假正类|[1]
False Positive Rate/FPR	|假正例率|[1]
Feature engineering	|特征工程|[1]
Feature map|特征映射|[1]
Feature selection|	特征选择|[1]
Feature vector|	特征向量|[1]
Featured Learning	|特征学习|[1]
Feedforward Neural Networks/FNN|前馈神经网络|[1]
Field Programmable Gated Array|现场可编程门阵列|[1]
Fine-tuning	|精调|[1]
Finite difference|有限差分|[1]
Fixed point equation|不动点方程|[1]
Flipping output	|翻转法|[1]
Fluctuation	|震荡|[1]
Forget gate|遗忘门|[1]
Forward stagewise algorithm|前向分步算法|[1]
Fourier transform|傅立叶变换|[1]
Frequentist	|频率主义学派|[1]
Frequentist probability|频率派概率|[1]
Full-rank matrix|满秩矩阵|[1]
Functional derivative|泛函导数|[1]
Functional neuron|功能神经元|[1]
# Letter G
[*Return*](https://github.com/SyncedAI00/Artificial-Intelligence-Terminology/blob/master/README.md)

英文/缩写|汉语|来源&扩展
---|---|---
Gain ratio|增益率|[1]
Game theory	|博弈论|[1]
Gated recurrent net/GRN|门控循环网络|[1]
Gaussian kernel function|高斯核函数|[1]
Gaussian Mixture Model	|高斯混合模型|[1]
General Problem Solving	|通用问题求解|[1]
Generalization|	泛化|[1]
Generalization error|	泛化误差|[1]
Generalization error bound|泛化误差上界|[1]
Generalized Lagrange function|广义拉格朗日函数|[1]
Generalized linear model	|广义线性模型|[1]
Generalized pseudolikelihood|广义伪似然|[1]
Generalized Rayleigh quotient	|广义瑞利商|[1]
Generalized score matching	|广义得分匹配|[1]
Generative Adversarial Networks/GAN|生成对抗网络|[1]
Generative Model	|生成模型|[1]
Generative moment matching network|生成矩匹配网络|[1]
Generator	|生成器|[1]
Genetic Algorithm/GA|遗传算法|[1]
Gibbs sampling|	吉布斯采样|[1]
Gini index|基尼指数|[1]
Global contrast normalization|全局对比度归一化|[1]
Global minimum	|全局最小|[1]
Global Optimization|全局优化|[1]
Gradient boosting tree|梯度提升树|[1]
Gradient Descent|	梯度下降|[1]
Graph theory	|图论|[1]
Ground-truth	|真相／真实|[1]
# Letter H
[*Return*](https://github.com/SyncedAI00/Artificial-Intelligence-Terminology/blob/master/README.md)

英文/缩写|汉语|来源&扩展
---|---|---
Hard  margin |硬间隔|[1]
Hard voting|硬投票|[1]
Harmonic mean	|调和平均|[1]
Hesse matrix|海赛矩阵|[1]
Hidden dynamic model|隐动态模型|[1]
Hidden layer|隐藏层|[1]
Hidden Markov Model/HMM|隐马尔可夫模型|[1]
Hierarchical clustering|层次聚类|[1]
Hilbert space|希尔伯特空间|[1]
Hinge loss function|合页损失函数|[1]
Hold-out|留出法|[1]
Homogeneous|同质|[1]
Hybrid computing|混合计算|[1]
Hyperparameter|超参数|[1]
Hypothesis|假设|[1]
Hypothesis test|假设检验|[1]
# Letter I
[*Return*](https://github.com/SyncedAI00/Artificial-Intelligence-Terminology/blob/master/README.md)

英文/缩写|汉语|来源&扩展
---|---|---
ICML|	国际机器学习会议|[1]
Identity matrix|单位矩阵|[1]
Improved iterative scaling/IIS|改进的迭代尺度法|[1]
Incremental learning	|增量学习|[1]
Independent and identically distributed/i.i.d.|	独立同分布|[1]
Independent Component Analysis/ICA|	独立成分分析|[1]
Independent subspace analysis|独立子空间分析|[1]
Indicator function|指示函数|[1]
Individual learner	|个体学习器|[1]
Induction	|归纳|[1]
Inductive bias	|归纳偏好|[1]
Inductive learning|	归纳学习|[1]
Inductive Logic Programming/ILP	|归纳逻辑程序设计|[1]
Inequality constraint|不等式约束|[1]
Information entropy	|信息熵|[1]
Information gain|	信息增益|[1]
Input layer|输入层|[1]
Insensitive loss	|不敏感损失|[1]
Inter-cluster similarity |	簇间相似度|[1]
International Conference for Machine Learning/ICML|	国际机器学习大会|[1]
Intra-cluster similarity|	簇内相似度|[1]
Intrinsic value	|固有值|[1]
Invert|求逆|[1]
Isometric Mapping/Isomap|等度量映射|[1]
Isotonic regression	|等分回归|[1]
Iterative Dichotomiser	|迭代二分器|[1]
# Letter J
[*Return*](https://github.com/SyncedAI00/Artificial-Intelligence-Terminology/blob/master/README.md)

英文/缩写|汉语|来源&扩展
---|---|---
Jensen-Shannon Divergence/JSD|JS 散度|[1]
# Letter k
[*Return*](https://github.com/SyncedAI00/Artificial-Intelligence-Terminology/blob/master/README.md)

英文/缩写|汉语|来源&扩展
---|---|---
Kernel method|	核方法|[1]
Kernel trick|	核技巧|[1]
Kernelized Linear Discriminant Analysis/KLDA |	核线性判别分析|[1]
K-fold cross validation	|k 折交叉验证／k 倍交叉验证|[1]
K-Means Clustering	|K - 均值聚类|[1]
K-Nearest Neighbours Algorithm/KNN|	K近邻算法|[1]
Knowledge base|知识库|[1]
Knowledge graph|知识图谱|[1]
Knowledge Representation|	知识表征|[1]
# Letter L
[*Return*](https://github.com/SyncedAI00/Artificial-Intelligence-Terminology/blob/master/README.md)

英文/缩写|汉语|来源&扩展
---|---|---
Label space|标记空间|[1]
Lagrange duality|拉格朗日对偶性|[1]
Lagrange multiplier|拉格朗日乘子|[1]
Laplace smoothing|拉普拉斯平滑|[1]
Laplacian correction|拉普拉斯修正|[1]
Latent Dirichlet Allocation/LDA |隐狄利克雷分布|[1]
Latent semantic analysis|潜在语义分析|[1]
Latent variable|隐变量|[1]
Law of large number|大数定理|[1]
Lazy learning |懒惰学习|[1]
Leaky ReLU|渗漏整流线性单元|[1]
Learner|	学习器|[1]
Learning by analogy|	类比学习|[1]
Learning rate	|学习率|[1]
Learning Vector Quantization/LVQ	|学习向量量化|[1]
Least squares regression tree|最小二乘回归树|[1]
Leave-One-Out/LOO	|留一法|[1]
Lebesgue-integrable|勒贝格可积|[1]
Left eigenvector|左特征向量|[1]
Leibniz’s rule|莱布尼兹法则|[1]
Linear Discriminant Analysis/LDA	|线性判别|[1]
Linear model|	线性模型|[1]
Linear Regression|	线性回归|[1]
Linear threshold units|线性阀值单元|[1]
Link function|	联系函数|[1]
Local conditional probability distribution|局部条件概率分布|[1]
Local contrast normalization|局部对比度归一化|[1]
Local Markov property|局部马尔可夫性|[1]
Local minimum	|局部最小|[1]
Log likelihood|	对数似然|[1]
Log odds/logit|	对数几率|[1]
Logistic Regression|Logistic 回归|[1]
Log-likelihood|	对数似然|[1]
Log-linear regression|	对数线性回归|[1]
Long-Short Term Memory/LSTM|	长短期记忆|[1]
Long-term dependency|长期依赖|[1]
Loopy belief propagation|环状信念传播|[1]
Loss function|	损失函数|[1]
Low rank matrix approximation|低秩矩阵近似|[1]
# Letter M
[*Return*](https://github.com/SyncedAI00/Artificial-Intelligence-Terminology/blob/master/README.md)

英文/缩写|汉语|来源&扩展
---|---|---
Machine translation/MT|	机器翻译|[1]
Macron-P	|宏查准率|[1]
Macron-R	|宏查全率|[1]
Main diagonal|主对角线|[1]
Majority voting|	绝对多数投票法|[1]
Manifold assumption|流形假设|[1]
Manifold learning|流形学习|[1]
Manifold tangent classiﬁer|流形正切分类器|[1]
Margin theory	|间隔理论|[1]
Marginal distribution|边缘分布|[1]
Marginal independence 	|边缘独立性|[1]
Marginal probability distribution|边缘概率分布|[1]
Marginalization 	|边际化|[1]
Markov Chain|马尔可夫链|[1]
Markov Chain Monte Carlo/MCMC|马尔可夫链蒙特卡罗方法|[1]
Markov Random Field|马尔可夫随机场|[1]
Matrix inversion|逆矩阵|[1]
Maximal clique|最大团|[1]
Maximum A Posteriori|最大后验|[1]
Maximum Likelihood Estimation/MLE|	极大似然估计／极大似然法|[1]
Maximum margin	|最大间隔|[1]
Maximum weighted spanning tree|	最大带权生成树|[1]
Max-Pooling	|最大池化|[1]
Mean product of Student t-distribution|学生 t 分布均值乘积|[1]
Mean squared error	|均方误差|[1]
Mean-covariance restricted Boltzmann machine|均值-协方差受限玻尔兹曼机|[1]
Measure theory|测度论|[1]
Meta-learner|	元学习器|[1]
Metric learning|度量学习|[1]
Micro-P	|微查准率|[1]
Micro-R	|微查全率|[1]
Minimal  Description Length/MDL|	最小描述长度|[1]
Minimax game	|极小极大博弈|[1]
Misclassification cost|	误分类成本|[1]
Mixture density network|混合密度网络|[1]
Mixture of experts|	混合专家|[1]
Moment matching|矩匹配|[1]
Momentum	|动量|[1]
Moral graph	|道德图／端正图|[1]
Multi-class classification	|多分类|[1]
Multi-document summarization	|多文档摘要|[1]
Multi-layer feedforward neural networks|	多层前馈神经网络|[1]
Multilayer Perceptron/MLP|	多层感知器|[1]
Multimodal learning|多模态学习|[1]
Multinomial distribution|多项分布|[1]
Multiple Dimensional Scaling|多维缩放|[1]
Multiple linear regression|	多元线性回归|[1]
Multi-response Linear Regression/MLR	|多响应线性回归|[1]
Multivariate normal distribution|多维正态分布|[1]
Mutual information|互信息|[1]
# Letter N
[*Return*](https://github.com/SyncedAI00/Artificial-Intelligence-Terminology/blob/master/README.md)

英文/缩写|汉语|来源&扩展
---|---|---
Naive bayes|朴素贝叶斯|[1]
Naive Bayes Classifier|朴素贝叶斯分类器|[1]
Named entity recognition|命名实体识别|[1]
Nash equilibrium|纳什均衡|[1]
Natural language generation/NLG|自然语言生成|[1]
Natural language processing|自然语言处理|[1]
Negative class|负类|[1]
Negative correlation|负相关法|[1]
Negative deﬁnite|负定|[1]
Negative Log Likelihood|负对数似然|[1]
Negative semideﬁnite|半负定|[1]
Neighbourhood Component Analysis/NCA|近邻成分分析|[1]
Neural Machine Translation|神经机器翻译|[1]
Neural Turing Machine|神经图灵机|[1]
Neuromorphic Computing|神经形态计算|[1]
Newton method|牛顿法|[1]
Conference on Neural Information Processing Systems/NIPS|国际神经信息处理系统会议|[1]
No Free Lunch Theorem/NFL|没有免费的午餐定理|[1]
Noise-contrastive estimation|噪音对比估计|[1]
Nominal attribute|列名属性|[1]
Non-convex optimization|非凸优化|[1]
Nonlinear model|非线性模型|[1]
Non-metric distance|非度量距离|[1]
Non-negative matrix factorization|非负矩阵分解|[1]
Non-ordinal attribute|无序属性|[1]
Non-Saturating Game|非饱和博弈|[1]
Norm|范数|[1]
Normalization|归一化|[1]
Nuclear norm|核范数|[1]
Numerical attribute|数值属性|[1]
Numerical optimization|数值优化|[1]
# Letter O
[*Return*](https://github.com/SyncedAI00/Artificial-Intelligence-Terminology/blob/master/README.md)

英文/缩写|汉语|来源&扩展
---|---|---
Objective function|目标函数|[1]
Oblique decision tree|斜决策树|[1]
Occam's razor|奥卡姆剃刀|[1]
Odds|几率|[1]
Off-Policy|离策略|[1]
One shot learning|一次性学习|[1]
One-Dependent Estimator/ODE|独依赖估计|[1]
On-Policy|在策略|[1]
Ordinal attribute|有序属性|[1]
Orthogonal matrix|正交矩阵|[1]
Orthonormal|标准正交|[1]
Out-of-bag estimate	|包外估计|[1]
Output layer|输出层|[1]
Output smearing|输出调制法|[1]
Overcomplete|过完备|[1]
Overfitting	|过拟合／过配|[1]
Oversampling|过采样|[1]
# Letter P
[*Return*](https://github.com/SyncedAI00/Artificial-Intelligence-Terminology/blob/master/README.md)

英文/缩写|汉语|来源&扩展
---|---|---
Paired t-test|成对 t 检验|[1]
Pairwise|成对型|[1]
Pairwise Markov property|成对马尔可夫性|[1]
Parallel tempering|并行回火|[1]
Parameter|参数|[1]
Parameter estimation|参数估计|[1]
Parameter tuning|调参|[1]
Parse tree|解析树|[1]
Partial derivative|偏导数|[1]
Particle Swarm Optimization/PSO|粒子群优化算法|[1]
Part-of-speech tagging|词性标注|[1]
Perceptron|感知机|[1]
Performance measure|性能度量|[1]
Permutation invariant|置换不变性|[1]
Plug and Play Generative Network|即插即用生成网络|[1]
Plurality voting|相对多数投票法|[1]
Polarity detection|极性检测|[1]
Polynomial kernel function|多项式核函数|[1]
Pooling|池化|[1]
Positive class|正类|[1]
Positive definite matrix|正定矩阵|[1]
Posterior probability|后验概率|[1]
Post-hoc test|后续检验|[1]
Post-pruning|后剪枝|[1]
potential function|势函数|[1]
Power method|幂方法|[1]
Precision|查准率／准确率|[1]
Prepruning|预剪枝|[1]
Principal component analysis/PCA|主成分分析|[1]
Principle of multiple explanations|多释原则|[1]
Prior knowledge|先验知识|[1]
Probability Graphical Model|概率图模型|[1]
Proximal Gradient Descent/PGD|近端梯度下降|[1]
Pruning|剪枝|[1]
Pseudo-label|伪标记|[1]
# Letter Q
[*Return*](https://github.com/SyncedAI00/Artificial-Intelligence-Terminology/blob/master/README.md)

英文/缩写|汉语|来源&扩展
---|---|---
Quadratic Programming|二次规划|[1]
Quantized Neural Network/QNN|量子化神经网络|[1]
Quantum computer|量子计算机|[1]
Quantum Computing|量子计算|[1]
Quasi Newton method|拟牛顿法|[1]
# Letter R
[*Return*](https://github.com/SyncedAI00/Artificial-Intelligence-Terminology/blob/master/README.md)

英文/缩写|汉语|来源&扩展
---|---|---
Radial Basis Function/RBF|径向基函数|[1]
Random Forest Algorithm|随机森林算法|[1]
Random walk|随机漫步 |[1]
Recall|查全率／召回率|[1]
Receiver Operating Characteristic/ROC|受试者工作特征|[1]
Rectified Linear Unit/ReLU|线性修正单元|[1]
Recurrent Neural Network|循环神经网络|[1]
Recursive neural network|递归神经网络|[1]
Reference model|参考模型|[1]
Regression|回归|[1]
Regularization|正则化|[1]
Regularizer|正则化项|[1]
Reinforcement learning/RL|强化学习|[1]
Relative entropy|相对熵|[1]
Reparametrization|重参数化|[1]
Representation learning|表征学习|[1]
Representer theorem|表示定理|[1]
Reproducing Kernel Hilbert Space/RKHS|再生核希尔伯特空间|[1]
Re-sampling|重采样法|[1]
Rescaling|再缩放|[1]
Reservoir computing|储层计算|[1]
Residual Mapping|残差映射|[1]
Residual Network|残差网络|[1]
Restricted Boltzmann Machine/RBM|受限玻尔兹曼机|[1]
Restricted Isometry Property/RIP|限定等距性|[1]
Reverse mode accumulation|反向模式累加|[1]
Re-weighting|重赋权法|[1]
Ridge regression|岭回归|[1]
Robustness|稳健性/鲁棒性|[1]
Root node|根结点|[1]
Rule Engine|规则引擎|[1]
Rule learning|规则学习|[1]
# Letter S
[*Return*](https://github.com/SyncedAI00/Artificial-Intelligence-Terminology/blob/master/README.md)

英文/缩写|汉语|来源&扩展
---|---|---
Saddle point|鞍点|[1]
Saddle-free Newton method|无鞍牛顿法|[1]
Sample space|样本空间|[1]
Sampling|采样|[1]
Score function|评分函数|[1]
Second derivative|二阶导数|[1]
Second-order method|二阶方法|[1]
Self-contrastive estimation|自对比估计|[1]
Self-Driving|自动驾驶|[1]
Self-Organizing Map/SOM|自组织映射|[1]
Semantic hashing|语义哈希|[1]
Semi-Definite Programming|半正定规划|[1]
Semi-naive Bayes classifiers|半朴素贝叶斯分类器|[1]
Semi-restricted Boltzmann Machine|半受限波尔兹曼机|[1]
Semi-Supervised Learning|半监督学习|[1]
semi-Supervised Support Vector Machine|半监督支持向量机|[1]
Sentiment analysis|情感分析|[1]
Separating hyperplane|分离超平面|[1]
Shannon entropy|香农熵|[1]
Sigmoid function|Sigmoid 函数|[1]
Similarity measure|相似度度量|[1]
Simulated annealing|模拟退火|[1]
Simultaneous localization and mapping/SLAM|同步定位与地图构建|[1]
Singular value|奇异值|[1]
Singular Value Decomposition|奇异值分解|[1]
Slack variables|松弛变量|[1]
Slowness principle|慢性原则|[1]
Smoothing|平滑|[1]
Smoothness prior|平滑先验|[1]
Soft margin|软间隔|[1]
Soft margin maximization|软间隔最大化|[1]
Soft voting|软投票|[1]
Sparse activation|稀疏激活|[1]
Sparse coding|稀疏编码|[1]
Sparse connectivity|稀疏连接|[1]
Sparse initialization|稀疏初始化|[1]
Sparse representation|稀疏表征|[1]
Sparsity|稀疏性|[1]
Specialization|特化|[1]
Spectral Clustering|谱聚类|[1]
Spectral radius|谱半径|[1]
Speech Recognition|语音识别|[1]
Spiking Neural Nets|脉冲神经网络|[1]
Splitting variable|切分变量|[1]
Squashing function|挤压函数|[1]
Stability-plasticity dilemma|可塑性-稳定性困境|[1]
Standard deviation|标准差|[1]
Stationary distribution|稳态分布|[1]
Stationary point|驻点|[1]
Statistical learning|统计学习|[1]
Status feature function|状态特征函数|[1]
Stochastic gradient descent|随机梯度下降|[1]
Stochastic Matrix|随机矩阵|[1]
Stochastic maximum likelihood|随机最大似然|[1]
Stratified sampling|分层采样|[1]
Structural  risk|结构风险|[1]
Structural risk minimization/SRM|结构风险最小化|[1]
Structured variational inference|结构化变分推断|[1]
Subspace|子空间|[1]
Supervised learning|监督学习／有导师学习|[1]
support vector expansion|支持向量展式|[1]
Support Vector Machine/SVM|支持向量机|[1]
Surrogat loss|替代损失|[1]
Surrogate function|替代函数|[1]
Symbolic learning|符号学习|[1]
Symbolism|符号主义|[1]
Synset|同义词集|[1]
# Letter T
[*Return*](https://github.com/SyncedAI00/Artificial-Intelligence-Terminology/blob/master/README.md)

英文/缩写|汉语|来源&扩展
---|---|---
Tangent plane|切平面|[1]
Tangent prop|正切传播|[1]
T-Distribution Stochastic Neighbour Embedding/t-SNE|T分布随机近邻嵌入|[1]
Tempered transition|回火转移|[1]
Tensor|张量|[1]
Tensor Processing Units/TPU|张量处理单元|[1]
The least square method|最小二乘法|[1]
Threshold|阈值|[1]
Threshold logic unit|阈值逻辑单元|[1]
Threshold-moving|阈值移动|[1]
Tiled convolution|平铺卷积|[1]
Time delay neural network|时延神经网络|[1]
Time Step|时间步骤|[1]
Tokenization|标记化|[1]
Training error|训练误差|[1]
Training instance|训练示例／训练例|[1]
Transductive learning|直推学习|[1]
Transfer learning|迁移学习|[1]
Treebank|树库|[1]
Tria-by-error|试错法|[1]
Triangulate|三角形化|[1]
Trigram|三元语法|[1]
True negative|真负类|[1]
True positive|真正类|[1]
True Positive Rate/TPR|真正例率|[1]
Turing Machine|图灵机|[1]
Twice-learning|二次学习|[1]
# Letter U
[*Return*](https://github.com/SyncedAI00/Artificial-Intelligence-Terminology/blob/master/README.md)

英文/缩写|汉语|来源&扩展
---|---|---
Underestimation|欠估计|[1]
Underfitting	|欠拟合／欠配|[1]
Undersampling	|欠采样|[1]
Understandability	|可理解性|[1]
Undirected graphical model|无向图模型|[1]
Unequal cost|	非均等代价|[1]
Unit norm|单位范数|[1]
Unitary matrix|酉矩阵|[1]
Unit-step function|	单位阶跃函数|[1]
Univariate decision tree	|单变量决策树|[1]
Unshared convolution|非共享卷积|[1]
Unsupervised  learning|	无监督学习／无导师学习|[1]
Unsupervised layer-wise training	|无监督逐层训练|[1]
Upsampling	|上采样|[1]
# Letter V
[*Return*](https://github.com/SyncedAI00/Artificial-Intelligence-Terminology/blob/master/README.md)

英文/缩写|汉语|来源&扩展
---|---|---
Vanishing Gradient Problem|梯度消失问题|[1]
Variational derivative|变分导数|[1]
Variational free energy|变分自由能|[1]
Variational inference|变分推断|[1]
VC Theory|VC维理论|[1]
Version space|版本空间|[1]
Virtual adversarial example|虚拟对抗样本|[1]
Viterbi algorithm|维特比算法|[1]
Von Neumann architecture|冯 · 诺伊曼架构|[1]
# Letter W
[*Return*](https://github.com/SyncedAI00/Artificial-Intelligence-Terminology/blob/master/README.md)

英文/缩写|汉语|来源&扩展
---|---|---
Weak learner|弱学习器|[1]
Weight|权重|[1]
Weight sharing|	权共享|[1]
Weighted voting|	加权投票法|[1]
Wasserstein GAN/WGAN|	Wasserstein生成对抗网络|[1]
Within-class scatter matrix|	类内散度矩阵|[1]
Word embedding|	词嵌入|[1]
Word sense disambiguation|	词义消歧|[1]
# Letter X
[*Return*](https://github.com/SyncedAI00/Artificial-Intelligence-Terminology/blob/master/README.md)

英文/缩写|汉语|来源&扩展
---|---|---
# Letter Y
[*Return*](https://github.com/SyncedAI00/Artificial-Intelligence-Terminology/blob/master/README.md)

英文/缩写|汉语|来源&扩展
---|---|---
# Letter Z
[*Return*](https://github.com/SyncedAI00/Artificial-Intelligence-Terminology/blob/master/README.md)

英文/缩写|汉语|来源&扩展
---|---|---
Zero-data learning|零数据学习|[1]
Zero-shot learning|零次学习|[1]
